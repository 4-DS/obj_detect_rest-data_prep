{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a281c4-d0fd-40c4-9849-91d0f1669678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebf8f4-cdbe-4ace-9fa5-e0300e2a1fc5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={\n",
    "    \"FILTER_EMPTY_GT\"    : False,\n",
    "    \"MIN_OBJECT_SIZE\"    : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0f470-dc4b-4605-b329-410a3b368ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6426737-251e-46c2-9fc4-66efd6389921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [\n",
    "        {STEP_NAME: \"data_load\", ENTITY_NAME: \"coco_datasets_images\"}, # images from data_load step\n",
    "        {STEP_NAME: \"data_load\", ENTITY_NAME: \"coco_datasets_annotations\"} # coco annotations from data_load step\n",
    "    ],\n",
    "    tmp_entities =\n",
    "    [    \n",
    "        { ENTITY_NAME: \"coco_datasets_images\"}, # extracted temporary images from Sinara Archive\n",
    "        { ENTITY_NAME: \"coco_datasets_annotations\"}, # extracted temporary annotations from Sinara Archive\n",
    "        { ENTITY_NAME: \"coco_train_dataset\"}, # temporary coco dataset for object detector train\n",
    "        { ENTITY_NAME: \"coco_eval_dataset\"}, # temporary coco dataset for object detector eval\n",
    "        { ENTITY_NAME: \"coco_test_dataset\"}, # temporary coco dataset for object detector test\n",
    "    ],\n",
    "    outputs = \n",
    "    [\n",
    "        { ENTITY_NAME: \"coco_train_dataset\"}, # coco dataset archived for object detector train\n",
    "        { ENTITY_NAME: \"coco_eval_dataset\"}, # coco dataset archived  for object detector eval\n",
    "        { ENTITY_NAME: \"coco_test_dataset\"}, # coco dataset archived  for object detector test\n",
    "    ]\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83adbbd-6f01-403f-b68b-2cc70343fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify all notebook wide libraries imports here\n",
    "# Sinara lib imports is left in the place of their usage\n",
    "from utils.coco import preview_coco_file, load_coco_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from utils.coco.utils import prepare_coco_dataset_images\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76aa12-771f-4a41-a999-599396e10cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "from sinara.archive import SinaraArchive\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "archive = SinaraArchive(spark)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a28711-f22f-40c9-b0fc-02187c04b559",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading coco_datasets_images and annotation files (from the previous step data_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16757091-17a6-4ba3-b922-d0a5528ae21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = substep.inputs(step_name = \"data_load\")\n",
    "tmp_entities = substep.tmp_entities()\n",
    "\n",
    "# copy data from previos step to tmp_entities\n",
    "archive.unpack_files_from_store_to_tmp(store_path=inputs.coco_datasets_images, tmp_entity_dir=tmp_entities.coco_datasets_images)\n",
    "archive.unpack_files_from_store_to_tmp(store_path=inputs.coco_datasets_annotations, tmp_entity_dir=tmp_entities.coco_datasets_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237b0fb-1bb0-48f8-9390-9e77304c7ec6",
   "metadata": {},
   "source": [
    "### Selecting object categories from general annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e75e71-5c24-49e9-90f0-7caaddbd44c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load annotation from json\n",
    "coco_annotation = load_coco_file(osp.join(tmp_entities.coco_datasets_annotations, \"instances_val2017.json\"))\n",
    "\n",
    "# Selection of object types for subsequent neural network training\n",
    "select_object_names = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\"]\n",
    "select_categories= [cat_info.copy() for cat_info in coco_annotation[\"categories\"] if cat_info[\"name\"] in select_object_names]\n",
    "for new_id, cat_info in enumerate(select_categories, 1):\n",
    "    cat_info[\"old_id\"] = cat_info[\"id\"]\n",
    "    cat_info[\"id\"] = new_id \n",
    "    \n",
    "# Select annotation object by select_categories\n",
    "reid_categories_ids = {cat_info[\"old_id\"]: cat_info[\"id\"] for cat_info in select_categories} # reidentification categories\n",
    "\n",
    "new_coco_annotations = []\n",
    "for annot in coco_annotation[\"annotations\"]:\n",
    "    new_annot = annot.copy()\n",
    "    category_id = new_annot[\"category_id\"]\n",
    "    if category_id in reid_categories_ids.keys():\n",
    "        new_annot[\"category_id\"] = reid_categories_ids[category_id]\n",
    "        new_coco_annotations.append(new_annot)\n",
    "        \n",
    "# apply new annotation\n",
    "coco_annotation[\"categories\"] = select_categories.copy()\n",
    "coco_annotation[\"annotations\"] = new_coco_annotations.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae3ce7-8d97-43e7-80a7-ae4c0ba94540",
   "metadata": {},
   "source": [
    "### Split Coco Dataset to Train, Valid and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632979d5-58ff-429f-bae7-c644c1dcc811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split to train, valid and test parts\n",
    "train_coco_images, val_coco_images = train_test_split(coco_annotation[\"images\"], test_size=0.33, random_state=42)\n",
    "val_coco_images, test_coco_images = train_test_split(val_coco_images.copy(), test_size=0.1, random_state=42)\n",
    "\n",
    "train_images_ids = [img_info[\"id\"] for img_info in train_coco_images]\n",
    "val_images_ids = [img_info[\"id\"] for img_info in val_coco_images]\n",
    "test_images_ids = [img_info[\"id\"] for img_info in test_coco_images]\n",
    "\n",
    "train_images_names = [img_info[\"file_name\"] for img_info in train_coco_images]\n",
    "val_images_names = [img_info[\"file_name\"] for img_info in val_coco_images]\n",
    "test_images_names = [img_info[\"file_name\"] for img_info in test_coco_images]\n",
    "\n",
    "train_coco_annotations = [annot.copy() for annot in coco_annotation[\"annotations\"] if annot[\"image_id\"] in train_images_ids]\n",
    "val_coco_annotations = [annot.copy() for annot in coco_annotation[\"annotations\"] if annot[\"image_id\"] in val_images_ids]\n",
    "test_coco_annotations = [annot.copy() for annot in coco_annotation[\"annotations\"] if annot[\"image_id\"] in test_images_ids]\n",
    "\n",
    "# create coco annotation for train dataset\n",
    "train_coco = coco_annotation.copy()\n",
    "train_coco[\"images\"] = train_coco_images\n",
    "train_coco[\"annotations\"] = train_coco_annotations\n",
    "\n",
    "# create coco annotation for train dataset\n",
    "val_coco = coco_annotation.copy()\n",
    "val_coco[\"images\"] = val_coco_images\n",
    "val_coco[\"annotations\"] = val_coco_annotations\n",
    "\n",
    "# create coco annotation for train dataset\n",
    "test_coco = coco_annotation.copy()\n",
    "test_coco[\"images\"] = test_coco_images\n",
    "test_coco[\"annotations\"] = test_coco_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da8ec3-5a2b-41c4-8d99-cfe2934d32d1",
   "metadata": {},
   "source": [
    "### Review Coco Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08899895-6ae5-414d-a956-aca9f272ffb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preview examples of data from train, valid and test dataset\n",
    "preview_coco_file(train_coco, img_folder=tmp_entities.coco_datasets_images, count=2)\n",
    "preview_coco_file(val_coco, img_folder=tmp_entities.coco_datasets_images, count=2)\n",
    "preview_coco_file(test_coco, img_folder=tmp_entities.coco_datasets_images, count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902fccd-ae38-466b-8f9c-31df58018690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# overview of the distribution of labeled data (detection)\n",
    "areas  = []\n",
    "counts = []\n",
    "categories = []\n",
    "categories_annotation = []\n",
    "\n",
    "anns = coco_annotation.get('annotations', [])\n",
    "for image in coco_annotation.get('images', []):\n",
    "    image_anns = [ann for ann in anns if ann['image_id'] == image['id']]\n",
    "    counts.append(len(image_anns))\n",
    "    \n",
    "    for ann in image_anns:\n",
    "        areas.append(ann.get('area'))\n",
    "        categories.append(ann.get('category_id'))\n",
    "    \n",
    "    categories_annotation += coco_annotation['categories']\n",
    "           \n",
    "counts = np.array(counts)\n",
    "areas  = np.array(areas)\n",
    "\n",
    "#overview of the distribution of detection marking areas throughout the entire dataset\n",
    "fig = px.histogram(areas, title='Area of objects at dataset images')\n",
    "fig.layout.yaxis.title = 'Objects count'\n",
    "fig.layout.xaxis.title = 'Area'\n",
    "fig.show()\n",
    "\n",
    "#erview of the distribution of marked objects throughout the entire dataset\n",
    "fig = px.histogram(counts, title='Objects count at dataset images')\n",
    "fig.layout.yaxis.title = 'Objects count'\n",
    "fig.layout.xaxis.title = 'Images count'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13221d-3524-497e-9761-fac7b0b4419f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save temporarily train, validation and test coco datasets to parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203dbcc-0356-476c-8e0e-28d37feb1dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save images for train, validation and test coco datasets to tmp_entities\n",
    "prepare_coco_dataset_images(train_coco, source_img_folder=tmp_entities.coco_datasets_images, dest_img_folder=tmp_entities.coco_train_dataset)\n",
    "prepare_coco_dataset_images(val_coco, source_img_folder=tmp_entities.coco_datasets_images, dest_img_folder=tmp_entities.coco_eval_dataset)\n",
    "prepare_coco_dataset_images(test_coco, source_img_folder=tmp_entities.coco_datasets_images, dest_img_folder=tmp_entities.coco_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e5954-40b3-44f3-b239-aed65260c2a5",
   "metadata": {},
   "source": [
    "### Save temporarily train, validation and test annotations to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23e4c6-4ee0-47c1-8bbb-ab5fe8cb5f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save annotations for each coco datasets\n",
    "train_annotation_path = osp.join(tmp_entities.coco_train_dataset, \"train_coco_annotations.json\")\n",
    "val_annotation_path = osp.join(tmp_entities.coco_eval_dataset, \"val_coco_annotations.json\")\n",
    "test_annotation_path = osp.join(tmp_entities.coco_test_dataset, \"test_coco_annotations.json\")\n",
    "\n",
    "with open(train_annotation_path, 'w') as f:\n",
    "    json.dump(train_coco, f, indent=4)\n",
    "\n",
    "with open(val_annotation_path, 'w') as f:\n",
    "    json.dump(val_coco, f, indent=4)\n",
    "    \n",
    "with open(test_annotation_path, 'w') as f:\n",
    "    json.dump(test_coco, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90687e97-db34-493a-b087-184f62fc2a34",
   "metadata": {},
   "source": [
    "### Archiving train, validation and test coco datasets to Sinara Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305aec9c-b4ae-4f15-bba2-65577c70d189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save tmp_entities (coco_train_dataset, coco_eval_dataset, coco_test_dataset) to outputs of step data_prep\n",
    "outputs = substep.outputs()\n",
    "\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.coco_train_dataset, store_path=outputs.coco_train_dataset)\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.coco_eval_dataset, store_path=outputs.coco_eval_dataset)\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.coco_test_dataset, store_path=outputs.coco_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dab20-5483-485e-b734-3042135d48d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
